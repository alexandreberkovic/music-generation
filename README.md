# Music Generation using Diffusion Modeling

## Overview

This project aims at using diffusion models to generate spectrograms from user-defined prompts, that can then easily be converted back into sound. It uses pre-trained models from HuggingFace notably, which are further fine-tuned for our specific task. 

## Installation & Packages

-  Pillow 9.4.0
-  transformers 4.28.1
-  torchvision 0.15.1
-  torchaudio 2.0.1
-  torch 2.0.0
-  tokenizers 0.13.3
-  scipy 1.9.1
-  scikit-learn 1.2.2
-  scikit-image 0.20.0
-  diffusers 0.16.1

## License

MIT
